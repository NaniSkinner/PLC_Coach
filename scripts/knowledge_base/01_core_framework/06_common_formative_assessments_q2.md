---
title: "Critical Question 2: Common Formative Assessments and Monitoring Learning"
type: "framework"
topics: ["common formative assessment", "CFA", "data analysis", "assessment design", "monitoring learning", "critical question 2"]
critical_question: [2]
author: "Solution Tree Framework"
publication_year: 2024
document_type: "core_framework"
---

# Critical Question 2: Common Formative Assessments and Monitoring Learning

## Introduction

Critical Question 2 - "How will we know when they've learned it?" - drives teams to develop systematic processes for monitoring student learning. While Question 1 establishes learning targets, Question 2 ensures teams have reliable evidence about student progress toward those targets. Common formative assessments (CFAs) are the primary tool for answering this question, providing timely, relevant data that informs both instruction and intervention.

## Understanding Common Formative Assessments

### What Makes an Assessment "Common"?

An assessment is "common" when collaborative team members:
- Design it together
- Administer it within the same timeframe
- Score it using agreed-upon criteria
- Analyze results collaboratively
- Use findings to inform practice

Common assessments create opportunities for teachers to learn from each other by comparing results across classrooms.

### What Makes an Assessment "Formative"?

Formative assessments are administered **during the learning process** to:
- Monitor student progress toward learning targets
- Identify students needing additional support
- Adjust instruction based on evidence
- Provide feedback to students about their learning

Unlike summative assessments that evaluate learning after instruction ends, formative assessments inform teaching while learning is still occurring.

### The Power of "Common Formative"

When assessments are both common AND formative, teams gain several advantages:

**For Teachers:**
- Protection from ineffective practices through comparison
- Opportunities to learn from colleagues achieving strong results
- Early warning system for students needing intervention
- Data to inform instructional adjustments

**For Students:**
- Consistent expectations across classrooms
- Multiple opportunities to demonstrate learning
- Timely feedback that guides improvement
- Reduced assessment anxiety through low-stakes practice

**For Teams:**
- Shared language for discussing student learning
- Basis for continuous improvement
- Evidence of effective instructional practices
- Foundation for collective responsibility

## Designing Quality Common Formative Assessments

### Alignment with Essential Standards

Every CFA item must connect directly to an essential standard. The tightest alignment occurs when:
- Questions require the same cognitive demand as the standard
- Content matches what was taught
- Vocabulary and context align with instruction
- Assessment format enables students to demonstrate the required skill

**Alignment Check:**
- Can you identify which specific essential standard each item assesses?
- Do items test understanding at the appropriate depth?
- Are prerequisites for the standard also assessed?

### Balance of Item Types

Effective CFAs include varied item formats:

**Selected Response (Multiple Choice, True/False, Matching):**
- *Strengths:* Efficient to score, can assess broad content
- *Limitations:* May not reveal student thinking, risk of guessing
- *Best For:* Factual knowledge, concept identification, procedural understanding

**Constructed Response (Short Answer, Extended Response):**
- *Strengths:* Reveals student reasoning, assesses explanation skills
- *Limitations:* Time-intensive to score, requires clear rubrics
- *Best For:* Explaining thinking, showing work, making connections

**Performance Tasks:**
- *Strengths:* Assesses application in authentic contexts
- *Limitations:* Most time-intensive to score and administer
- *Best For:* Complex skills, real-world application, transfer of learning

**Recommendation:** Most CFAs should include a mix of formats, weighted toward selected and short constructed response for efficiency.

### Appropriate Rigor

Assessment rigor must match the cognitive demand of essential standards:

**Lower-Complexity Standards:** (Remember, Understand)
- Items requiring recall of facts
- Questions asking for definitions or identification
- Tasks involving basic procedures

**Moderate-Complexity Standards:** (Apply, Analyze)
- Multi-step problem-solving
- Comparing and contrasting concepts
- Applying learned procedures to new situations

**High-Complexity Standards:** (Evaluate, Create)
- Developing original arguments or solutions
- Evaluating quality of evidence or reasoning
- Creating new products demonstrating understanding

**Common Mistake:** Making assessments easier than standards require, leading to inflated proficiency estimates.

### Clear Proficiency Criteria

Before administering a CFA, teams must agree on:
- What constitutes proficient performance
- How many points or what percentage indicates proficiency
- What common errors represent misunderstanding vs. careless mistakes
- Whether partial credit is appropriate and how it's assigned

This consensus prevents inconsistent scoring across teachers.

### Manageable Length

CFAs should be long enough to provide reliable data but not so long that they consume excessive instructional time:

**Elementary (Grades K-2):** 10-15 minutes
**Elementary (Grades 3-5):** 15-25 minutes
**Secondary:** 20-35 minutes

**Balance Considerations:**
- Longer assessments provide more complete data
- Shorter assessments allow more frequent administration
- Assessment time reduces available instruction time

Most teams find that assessing 3-5 essential standards per CFA creates appropriate length and focus.

## Administering Common Formative Assessments

### Timing and Frequency

**General Guidance:**
- Administer CFAs every 2-4 weeks
- More frequent for struggling students or complex content
- Less frequent for standards requiring extended instructional time

**Scheduling Principles:**
- Allow enough instruction time before assessing
- Leave time for intervention before summative assessment
- Coordinate across grade levels to avoid overloading students
- Consider pacing for all subjects, not just your team's

### Maintaining Similar Conditions

While some variation is inevitable, teams should strive for comparable assessment conditions:

**Standardize When Possible:**
- Time allotted for completion
- Access to resources (calculators, reference materials)
- Format (paper/pencil vs. digital)
- Whether students can ask clarifying questions

**Allow Flexibility For:**
- Timing of day (morning vs. afternoon)
- Classroom arrangement
- Accommodations for IEP/504 students
- Minor procedural differences

The goal is meaningful comparison, not absolute uniformity.

### Scoring Protocols

Teams should establish clear processes for scoring:

**Option 1: Individual Scoring with Common Rubric**
- Each teacher scores their own students' work
- All use the agreed-upon answer key and rubric
- Consistency checks through sample scoring

**Option 2: Collaborative Scoring**
- Team scores assessments together
- Discuss scoring dilemmas as they arise
- Ensures absolute consistency across classrooms

**Option 3: Digital Scoring**
- Selected response auto-scored by assessment platform
- Teachers score constructed response independently
- System aggregates results

Most teams use Option 1 for efficiency, with periodic checks of scoring consistency.

## Analyzing Common Formative Assessment Results

### The Data Analysis Meeting

Following CFA administration, teams dedicate meeting time to collaborative analysis:

**Typical Agenda** (60 minutes):
1. Context Review (5 min) - Clarify assessed standards, discuss any administration issues
2. Individual Prediction (3 min) - Each teacher predicts results privately
3. Data Observation (10 min) - Silent review of results, noting patterns
4. Collaborative Analysis (25 min) - Discuss findings, explore explanations
5. Action Planning (15 min) - Identify interventions, plan re-teaching
6. Reflection (2 min) - Evaluate the analysis process

### Levels of Analysis

**Level 1: Overall Proficiency**
- What percentage of students demonstrated proficiency?
- How does this compare to expectations?
- Are results consistent with prior assessments?

**Level 2: Item-Level Analysis**
- Which specific questions did students struggle with?
- What patterns emerge in incorrect responses?
- Did particular distractors attract many students?

**Level 3: Comparison Across Classrooms**
- Are results similar across all teachers?
- Where do significant differences exist?
- What might explain variation in outcomes?

**Level 4: Individual Student Analysis**
- Which students need Tier 2 intervention?
- Which students are ready for extension?
- What specific skills does each struggling student need?

Effective teams move through all four levels, though not every CFA requires equal emphasis on each.

### Powerful Questions for Analysis

**Understanding Results:**
- What surprises us about these results?
- What patterns do we notice across items or students?
- Which of our predictions proved accurate or inaccurate?

**Exploring Causation:**
- What instructional decisions might have influenced these outcomes?
- How did pacing affect student learning?
- What strategies seemed most effective?

**Planning Action:**
- Which concepts need whole-class re-teaching?
- What alternative approaches should we try?
- Which students need additional time and support?
- How will we know if our adjustments work?

## From Analysis to Action

### Instructional Adjustments

When CFA results reveal gaps in understanding:

**Whole-Class Re-Teaching:**
- Identify concepts most students haven't mastered
- Plan lessons using different instructional approaches
- Provide additional practice opportunities
- Re-assess to verify improved understanding

**Small-Group Targeted Instruction:**
- Group students by specific skill needs
- Provide focused instruction on particular misconceptions
- Use flexible grouping that changes based on data
- Monitor progress through quick checks

**Individual Conferencing:**
- Meet briefly with students showing unique struggles
- Diagnose specific misunderstandings
- Provide tailored support and practice
- Follow up to ensure improved understanding

### Identifying Students for Intervention and Extension

CFAs provide the data needed to answer Questions 3 and 4:

**Tier 2 Intervention Candidates:**
- Students scoring below proficiency threshold
- Those showing declining performance trends
- Students with gaps in prerequisite skills
- Learners requiring additional time and support

**Extension Candidates:**
- Students scoring at or above proficiency
- Those demonstrating mastery efficiently
- Learners ready for deeper or broader challenges
- Students who could handle accelerated pacing

### Sharing Effective Practices

When comparative analysis reveals differences in results:

**Learning from Success:**
- Teachers with strong results share their approaches
- Team discusses which strategies might transfer
- Plan for observation or co-teaching
- Try adapted approaches in other classrooms

**Important Mindset:** The goal is learning, not evaluation. Teachers with lower results aren't "bad teachers" - they're experiencing different outcomes that create learning opportunities for everyone.

## Common Challenges and Solutions

### Challenge 1: "We Don't Have Time"

**Problem:** Teams feel they can't spare instructional time for CFAs.

**Solution:**
- CFAs replace, not supplement, other assessment
- Time invested in CFAs is recovered through more focused instruction
- Intervention based on timely data is more efficient than remediation later
- Start with one CFA per quarter and gradually increase frequency

### Challenge 2: Scoring Inconsistency

**Problem:** Teachers score the same student work differently.

**Solution:**
- Develop specific answer keys and rubrics together
- Score sample responses as a team to calibrate
- Periodically check consistency by scoring common papers
- Use digital platforms that ensure consistent scoring of selected response

### Challenge 3: Using Data for Teacher Evaluation

**Problem:** Teachers fear CFAs will be used to judge their effectiveness.

**Solution:**
- Establish clear norms that CFAs inform learning, not evaluation
- Administrators model vulnerability by sharing their own struggles
- Focus on patterns and learning, not individual teacher comparison
- Keep CFA data separate from formal evaluation processes

### Challenge 4: Students Don't Take CFAs Seriously

**Problem:** Low stakes lead students to rush or guess rather than showing their best work.

**Solution:**
- Communicate importance of CFAs for planning support
- Count CFAs as minor grades (small percentage)
- Provide specific feedback to students on results
- Show students how CFAs lead to help they receive
- Celebrate improved performance on subsequent assessments

### Challenge 5: Creating Quality Assessments Takes Too Much Time

**Problem:** Designing CFAs is time-consuming.

**Solution:**
- Start with released state test items
- Adapt publisher assessments to focus on essentials
- Access district-developed CFAs if available
- Improve assessments over time rather than seeking perfection initially
- Divide item-writing tasks among team members

## Building Team Capacity for Assessment Design

### Assessment Literacy Skills

Effective CFA design and use requires that teams understand:
- How to write items aligned to standards
- What different item types can and cannot assess
- How to create scoring rubrics
- How to interpret various data displays
- How to establish defensible proficiency criteria

### Professional Learning Opportunities

Teams deepen assessment literacy through:
- Studying resources on quality assessment design
- Analyzing strong and weak assessment items
- Examining released state assessment items
- Scoring student work collaboratively
- Attending workshops on assessment design

### Continuous Improvement

Assessment quality improves over time through:
- Reflection after each CFA administration
- Revision of confusing or misaligned items
- Addition of items covering gaps
- Adjustment of proficiency criteria based on experience
- Documentation of lessons learned

## Technology Tools for CFAs

### Assessment Platforms

Digital tools can streamline CFA administration and analysis:

**Features to Seek:**
- Collaborative item bank building
- Auto-scoring of selected response items
- Immediate data reporting
- Item-level analysis displays
- Student progress tracking

**Popular Platforms:**
- Google Forms (free, basic functionality)
- Illuminate Education
- Mastery Connect
- Schoology Assessments
- Canvas Quizzes

### Data Display Tools

Teams need ways to visualize CFA results:
- Charts showing proficiency by standard
- Item analysis spreadsheets
- Comparison across classrooms
- Individual student tracking

Simple spreadsheets often suffice, but more sophisticated platforms can save time.

### Low-Tech Alternatives

Schools without digital assessment tools can still use CFAs effectively:
- Paper assessments scored by hand
- Data recorded in shared spreadsheets
- Charts created on poster paper
- Student work samples examined together

The process matters more than the technology.

## Connection to Other Critical Questions

### Driving Question 3 (Intervention)

CFA results identify students needing additional support:
- Who needs intervention, not just that intervention is needed
- What specific skills require additional instruction
- Whether current interventions are working
- When students are ready to exit intervention

### Informing Question 4 (Extension)

CFA results also identify students ready for enriched learning:
- Who has mastered essential standards
- What depth or breadth of extension is appropriate
- Whether extension activities are sufficiently challenging
- When students need to move to new content

### Guiding Question 1 (Essential Standards)

Over time, CFA results inform refinement of essential standards:
- Which standards prove most critical for future success
- Where students consistently struggle despite good instruction
- What prerequisites need emphasis
- How much time various standards truly require

## Conclusion

Common formative assessments are the beating heart of the PLC process. They transform abstract conversations about learning into concrete discussions grounded in evidence. When teams develop the discipline to regularly assess student learning, analyze results collaboratively, and adjust practice based on findings, they create powerful conditions for continuous improvement.

Effective CFA use requires:
- Assessments tightly aligned to essential standards
- Regular administration with timely analysis
- Structured protocols for collaborative data review
- Rapid translation of insights into instructional action
- Transparent sharing of results across classrooms
- Focus on learning from data rather than judgment

Building this culture takes time. Many teams initially create superficial CFAs, analyze data in passing, or struggle to translate findings into effective action. However, as teams develop assessment literacy and establish productive routines, CFAs become increasingly powerful tools for ensuring all students learn at high levels.

The question is not whether to use common formative assessments - research overwhelmingly demonstrates their value. The question is whether teams will commit to the disciplined practice required to use CFAs well. Those who do find that the investment pays tremendous dividends in both student achievement and professional learning.

## Reflection Questions

1. How frequently does your team administer common formative assessments? Is this frequent enough to inform timely intervention?

2. To what extent are your CFAs truly aligned to essential standards? How do you know?

3. What protocols guide your team's analysis of CFA results? How effective are these processes?

4. How quickly does your team move from CFA analysis to instructional action? What prevents faster response?

5. What would help your team design better CFAs or use assessment data more effectively?
