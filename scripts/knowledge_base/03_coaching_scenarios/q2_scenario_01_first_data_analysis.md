---
title: "Coaching Scenario: First Data Analysis Meeting for New PLC Team"
type: "coaching_scenario"
topics: ["data analysis", "CFA results", "first meeting", "team dynamics", "critical question 2"]
critical_question: [2]
grade_level: "elementary"
subject: "literacy"
scenario_type: "Q2_data_analysis"
difficulty: "foundational"
author: "AI PLC Coach"
publication_year: 2024
document_type: "coaching_scenario"
---

# Coaching Scenario: First Data Analysis Meeting for New PLC Team

## Context

Lisa is a 2nd-grade teacher whose team just administered their first common formative assessment on reading fluency and comprehension. They've scheduled a meeting to "look at the data" but no one on the team has experience with structured data analysis. Lisa is nervous about how the meeting will go and worried that colleagues will be defensive if their results are lower than others'.

**Team Composition:**
- 5 second-grade teachers
- First year as formal PLC
- Mix of experience (3 to 20+ years)
- Good relationships but haven't analyzed data together before

**Current Situation:**
- Administered CFA on reading skills last week
- Everyone scored their own students
- Results range from 58% to 84% proficiency across classrooms
- Data analysis meeting scheduled for tomorrow
- No protocol or agenda established

## The Coaching Conversation

### Turn 1: Teacher Opens

**Lisa:** I'm really nervous about our meeting tomorrow. We gave our first common assessment on reading, and I know the results vary a lot across our classrooms. I've seen the summary - one teacher's kids did really well (84% proficient) and another teacher's students struggled more (58%).

I'm worried that when we look at the data together, people will get defensive or competitive. What if the teacher with lower results feels attacked? Or what if the teacher with high results gets smug? We have good relationships now, and I don't want data to ruin that. Should we even look at results by classroom, or should we just look at grade-level overall?

**Coach's Purpose:** Address emotional concern first, reframe data analysis as learning opportunity not judgment, introduce structured protocols to prevent defensiveness.

**Coach Response:**

Lisa, your concern shows you care about your team relationships, and that's valuable. But let me reframe how you're thinking about this. Right now, you're seeing data as threat - something that might expose weaknesses or create competition. But in effective PLCs, data is a gift - it's information that helps everyone get better.

Here's the key: Data becomes threatening when there's no structure. But when teams use a protocol that focuses on learning and improvement, not judgment, data analysis actually strengthens relationships. Teachers appreciate seeing that everyone struggles with something, and they're grateful when colleagues share strategies that work.

Let me be direct: Yes, you absolutely should look at results by classroom. Here's why - if Teacher A's students performed at 84% and Teacher B's at 58%, that 26-point difference is valuable information. Either Teacher A is doing something others could learn from, or there's a difference in student populations, or there's inconsistent scoring. All of these are worth understanding.

Hiding individual results treats your team like they can't handle reality. Showing results with a structured, learning-focused protocol treats them like professionals capable of learning from evidence.

Does that shift your thinking at all?

---

### Turn 2: Teacher Sees Value but Needs Structure

**Lisa:** That does make sense. I guess I have been thinking about data as exposing problems rather than showing us opportunities to learn. And you're right that the 26-point gap is information we need to understand.

But you keep mentioning a "structured protocol." We don't have one. Our meeting agenda literally just says "Analyze assessment data." What should we actually DO during the meeting? What's the structure that keeps this productive instead of defensive?

**Coach's Purpose:** Provide concrete data analysis protocol, explain rationale for each step, give her something she can facilitate.

**Coach Response:**

I'm going to give you a step-by-step protocol you can use tomorrow. This is adapted from protocols used by high-performing PLC teams:

**Data Analysis Protocol (60 minutes):**

**Step 1: Set Norms (5 minutes)**
Before looking at any data, review norms:
- "We're here to learn, not judge"
- "Data describes performance, not defines people"
- "Everyone has strengths and areas for growth"
- "We share strategies generously"
- "Confidentiality - data stays in this room"

**Step 2: Context Setting (5 minutes)**
- Review what you assessed (reading fluency and comprehension)
- Note any administration differences
- Share any concerns about the assessment itself

**Step 3: Individual Prediction (3 minutes)**
Before showing data, each person privately writes:
- "I predict X% of my students were proficient"
- "I predict the skills they struggled with most were..."

**Step 4: Silent Data Observation (7 minutes)**
Display data (by classroom and by item)
Everyone silently reviews, taking private notes on:
- Overall patterns
- Surprising results
- Questions that arise

**Step 5: Collaborative Observation (15 minutes)**
Round-robin sharing: "I notice..." (not "I think" or "I interpret")
- What patterns do you see?
- What surprises you?
- What questions arise?

**Step 6: Analysis and Inquiry (20 minutes)**
Discuss:
- Where are students strong across all classrooms?
- Where do significant gaps exist?
- What might explain differences across classrooms?
- What do successful results have in common?

**Step 7: Action Planning (10 minutes)**
- What will we do differently based on this data?
- Who needs intervention?
- What strategies will we share?
- When will we re-assess?

Does this give you a structure you could use tomorrow?

---

### Turn 3: Teacher Questions Specific Steps

**Lisa:** Yes, this is really helpful! A few questions about specific steps:

Why do the individual predictions matter? Isn't that just setting people up to feel bad if they were wrong?

And in Step 6, you asked "What might explain differences across classrooms?" - I feel like that's where defensiveness might show up. If someone's results are lower, won't they feel like we're interrogating them about what they did wrong?

**Coach's Purpose:** Explain rationale for predictions (surface assumptions), provide language for facilitating sensitive discussions about differences.

**Coach Response:**

Great questions! Let me explain the thinking behind each:

**Why Predictions?**
Predictions surface our assumptions. Often teachers predict worse results than reality - then they're pleasantly surprised. Sometimes they predict better - which prompts reflection on why results differed from expectations. The point isn't to be "right" or "wrong," it's to become aware of our own assumptions before we see data.

You might frame it this way: "We're making predictions not to test ourselves, but to notice what assumptions we're bringing to this data. There's no right answer here."

**How to Discuss Differences Without Defensiveness:**

Here's the key language shift:

**Don't ask:** "Why were your results lower?" (implies fault)

**Do ask:** "What do we notice about where students struggled?" (focuses on students, not teacher)

**Don't say:** "What did you do differently?" (implies judgment)

**Do say:** "What strategies did we each use? Let's share approaches and see what we notice." (implies collaboration)

**Example Facilitation:**
"I notice Teacher A's students scored higher on comprehension questions. Teacher A, what approach did you use for teaching comprehension? Let's all hear it - maybe there's something we could try."

Then ask others: "What approaches did others use? How were they similar or different?"

This frames it as sharing strategies, not defending lower results. The teacher with lower results participates in the conversation as a colleague exploring approaches, not as someone being corrected.

Make sense?

---

### Turn 4: Teacher Asks About Hard Conversations

**Lisa:** That helps. But what if we discover that one teacher really is doing something that isn't working? Like, what if we find out someone isn't teaching a skill we all agreed to teach? Or what if the lower results are because a teacher isn't following our common pacing?

I don't want to ignore real problems, but I also don't want our first data meeting to turn into confrontation.

**Coach's Purpose:** Distinguish between first meeting and ongoing accountability, provide guidance for addressing real concerns without destroying trust.

**Coach Response:**

This is an important distinction, Lisa. Let me separate two scenarios:

**Scenario 1: Discovery of Different Approaches**
If you discover someone used a different instructional approach, that's not necessarily a problem - it might be a learning opportunity. Maybe their approach worked well and others should consider it. Maybe it didn't work well and they're open to trying something different. This is normal variation and perfect for collaborative discussion.

**Scenario 2: Discovery of Not Teaching Agreed Content**
If you discover someone didn't teach content the team agreed to teach, that's a different issue. But here's the thing: you're not going to resolve that in your first data meeting. Your first meeting is about building a culture of using data to learn. If you discover a significant implementation concern, note it but don't address it publicly in the moment.

**How to Handle It:**

**In the meeting:**
Stay focused on student learning, not adult compliance. Ask: "What do students need next based on these results?"

**After the meeting:**
If you're the team lead, have a private conversation: "I noticed the data showed students struggling with X. Our team agreed to teach X by week 3. I'm wondering what happened?"

This could be:
- Misunderstanding about pacing
- Legitimate obstacle (students weren't ready, needed more time elsewhere)
- Forgot the agreement
- Chose not to follow agreement

You handle each differently, but you don't do it publicly in the first data meeting.

**First Meeting Goal:** Build trust that data is safe and useful
**Later Meetings:** Address implementation fidelity once trust exists

Does that distinction help?

---

### Turn 5: Teacher Asks About Data Display

**Lisa:** Yes, that makes sense. OK, one more practical question - how should I display the data? Should I make a PowerPoint? A handout? Just use a spreadsheet?

And should I show each teacher's name, or use codes like "Teacher A, Teacher B"? I feel like using names makes it more transparent, but codes might feel safer for our first time.

**Coach's Purpose:** Provide practical guidance on data visualization, address transparency question thoughtfully.

**Coach Response:**

Great practical question! How you display data matters. Here's my guidance:

**Best Format:**
Create a simple, visual display that shows patterns quickly. I'd recommend:

**Display 1: Overall Proficiency by Classroom**
Simple bar chart showing % proficient for each teacher's class
Use names, not codes (more on this below)

**Display 2: Item Analysis**
Table or chart showing % of all students who got each question correct
This shows which skills were strong/weak grade-wide

**Display 3: Student Names for Intervention**
Actual student names needing Tier 2 (from all classrooms mixed together)

**Media:** Use a shared screen or print handouts everyone can annotate. Avoid PowerPoint slides people can't reference back to.

**Names vs. Codes:**

I strongly recommend using names from the start. Here's why:

**Codes feel safer but send wrong message:**
- "We need to hide who we are"
- "This data is shameful"
- "We can't handle transparency"

**Names send better message:**
- "We're professionals looking at reality together"
- "There's nothing shameful about data"
- "We trust each other with truth"

However, I'd name this choice explicitly: "I'm showing everyone's results by name because we're building a culture of transparency and trust. These results don't define us as teachers - they're just information about student performance on one assessment on one day."

If someone objects to names, respect that and use codes. But frame it as professional transparency from the start.

Make sense?

---

### Turn 6: Teacher Feels More Confident but Worries About Facilitation

**Lisa:** This is all really helpful. I'm feeling more confident about the structure. But I'm nervous about facilitating the conversation. What if people don't follow the protocol? What if someone gets defensive anyway? What if the conversation goes off track?

I'm not the official team leader - we're supposed to be collaborative. How do I facilitate without seeming bossy?

**Coach's Purpose:** Build her facilitation confidence, provide specific language for keeping things on track, address authority question.

**Coach Response:**

Lisa, let me ease your concern: someone on your team needs to facilitate, and it sounds like you're willing to step up. That's leadership, not bossiness. The key is framing yourself as guide, not boss.

**Opening Frame for Meeting:**
"I know we're all new to data analysis meetings, so I found a protocol successful PLC teams use. I'm happy to help us follow it today, but anyone else could facilitate next time. Should we give it a try?"

This positions you as helper, not authority, and makes facilitation a rotating role.

**Facilitation Moves for Common Challenges:**

**If someone gets defensive:**
"I hear that this data feels personal. Can we return to our norm - data describes performance, not people? This is about what students need, not judgment of anyone here."

**If conversation goes off track:**
"This is an interesting conversation, but let's return to our student data. Can we revisit this topic at another time?"

**If someone dominates:**
"Let's hear from others. What do people who haven't shared yet notice?"

**If silence happens:**
"Let's take 2 minutes to write individual observations, then share."

**If someone blames students:**
"I hear your frustration. And, we can only control our instruction. What's in our control to try differently?"

**Key Mindset:** You're not controlling the conversation; you're protecting the process. The protocol is the authority, not you. You're just helping the team follow it.

Would you feel comfortable trying those moves?

---

### Turn 7: Teacher Asks About Follow-Through

**Lisa:** Yes, I think I could do that. OK, so let's say our meeting goes well. We follow the protocol, look at data without defensiveness, and identify some actions to take - like students who need intervention and strategies to share.

But what happens after the meeting? How do we make sure people actually DO what we agreed to do? We're good at having conversations, but not always good at follow-through. How do we hold each other accountable without it feeling like policing?

**Coach's Purpose:** Address accountability question, introduce documentation and check-ins, frame as support not surveillance.

**Coach Response:**

Excellent question! You're thinking about the full cycle, not just the meeting. Here's the truth: many teams have great data conversations and then nothing changes because there's no follow-through system. Let me give you simple structures:

**Accountability Structure:**

**1. Document Commitments**
End your meeting by explicitly recording:
- WHO will do WHAT by WHEN
- Which students need intervention? Who will provide it?
- What strategy will we try? When will we implement it?
- When will we reassess?

Record this in shared document everyone can access.

**2. Begin Next Meeting with Follow-Up**
Start every meeting with: "Last time we agreed to X. How did it go?"
- Not in accusatory way, but genuine curiosity
- "What worked? What didn't? What did we learn?"

This creates expectation that commitments matter.

**3. Frame as Support, Not Surveillance**
"We're checking in because we all said this matters. I want to hear how it went for you - what supported it? What got in the way?"

If someone didn't follow through:
"What kept you from being able to do that? How can we help?"

This assumes good intent and obstacles, not laziness.

**4. Leader Participation**
If you facilitate, model this: "I committed to trying X strategy. Here's what happened..."

Vulnerability builds trust.

**Key Mindset:** You're building a culture where commitments matter because student learning matters, not because someone's checking up on you. Big difference.

Does that feel workable?

---

### Turn 8: Teacher Confirms Plan and Feels Ready

**Lisa:** Yes! OK, I think I'm ready. Let me summarize my plan to make sure I have it right:

**Before Meeting:**
- Create simple data displays (bar chart of proficiency, item analysis table, student intervention list)
- Print handouts for everyone
- Send the protocol agenda ahead of time

**During Meeting:**
- Set norms about learning, not judging
- Use the 7-step protocol you gave me
- Facilitate with focus on student needs, not teacher evaluation
- Document who will do what by when

**After Meeting:**
- Follow up on commitments at start of next meeting
- Frame check-ins as support, not policing
- Model by sharing my own experiences

Is that the full picture? And is there anything I should do if the meeting doesn't go well - like if people resist the protocol or get really defensive?

**Coach's Purpose:** Affirm her plan, provide contingency guidance, offer ongoing support.

**Coach Response:**

Lisa, your plan is perfect. You've got the full picture. I'm confident this will go well because you have clear structure and you're thinking about the culture you want to build, not just the mechanics.

**If Meeting Doesn't Go Well:**

If people resist the protocol:
"I know this is new and maybe feels awkward. Could we try it just for today and then reflect on whether it was helpful? We can adjust for next time."

If people get defensive despite your efforts:
"I notice this feels uncomfortable for some people. Let's pause and talk about what would make data analysis feel safer and more productive for our team."

Sometimes teams need to explicitly negotiate how they'll work with data. That's OK - it's part of the process.

**Worst Case Scenario:**
If the meeting goes really poorly - people shut down, get angry, refuse to engage - end early. Say: "I think we need help figuring out how to do this well. Let me reach out to our instructional coach (or principal, or PLC coordinator) to get support for our team."

You don't have to figure everything out alone.

**Most Likely Scenario:**
Your meeting will be a bit awkward (first times always are), but people will appreciate the structure and you'll learn together. It'll get easier and more natural over time.

Touch base with me after the meeting? I'd love to hear how it went and what you learned.

---

## Coaching Analysis

### Effective Coaching Moves Used

**1. Reframed Data from Threat to Gift**
Shifted Lisa's mindset from fearing data will harm relationships to seeing it as tool for improvement.

**2. Provided Concrete Protocol**
Gave step-by-step structure that Lisa could immediately use, not vague guidance.

**3. Addressed Emotional/Social Dynamics**
Spent significant time on defensive reactions, team relationships, and psychological safety - not just technical data analysis.

**4. Anticipated Challenges**
Proactively addressed likely obstacles: defensiveness, off-track conversations, non-compliance.

**5. Built Facilitation Capacity**
Provided specific language and moves for common facilitation challenges.

**6. Normalized Struggle**
Repeatedly framed first attempts as naturally awkward, removing pressure for perfection.

**7. Offered Contingency Plans**
Addressed "what if it goes badly?" scenarios, giving Lisa confidence to proceed.

### Key PLC Concepts Demonstrated

- **Data-Driven Decision Making:** Using evidence to inform instruction and intervention
- **Collaborative Data Analysis:** Teams examining results together, not in isolation
- **Psychological Safety:** Creating conditions where data is safe to discuss
- **Structured Protocols:** Using frameworks to guide difficult conversations
- **Collective Responsibility:** Focus on "our students" and shared learning
- **Action Orientation:** Data analysis must lead to changed practice
- **Accountability Systems:** Follow-through structures for commitments

### Likely Outcomes

If Lisa implements this coaching advice:
- **Immediate:** First data meeting will be structured and productive
- **Short-term:** Team will identify intervention students and share strategies
- **Medium-term:** Team will develop routine for data analysis
- **Long-term:** Culture of transparency and continuous improvement will develop

### Potential Challenges Ahead

1. **First Meeting Awkwardness:** Protocol may feel forced initially
2. **Defensive Reactions:** Despite precautions, some teachers may still feel judged
3. **Follow-Through Issues:** Commitments may not be kept between meetings
4. **Inconsistent Facilitation:** Different facilitators may apply protocol differently

The coach has positioned Lisa well to handle these challenges by providing both structures and interpersonal strategies.

## Reflection Questions for Coaches

1. How did the coach balance Lisa's emotional concerns with practical guidance?

2. What evidence suggests the coach was building Lisa's long-term capacity, not just solving one meeting?

3. How did the coach make data analysis feel manageable for a team new to the practice?

4. What follow-up coaching might Lisa need after her first data meeting?

5. How might this coaching conversation differ for an experienced PLC team having data analysis problems?
